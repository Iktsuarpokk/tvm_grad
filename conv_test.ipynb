{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Test, self).__init__()\n",
    "        self.score4 = nn.Conv2d(23, 22, 1)\n",
    "        self.score_fr = nn.Conv2d(22, 21, 1, bias=False)\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        h = inp\n",
    "        h = self.score4(h)\n",
    "        h = self.score_fr(h)\n",
    "\n",
    "        return h\n",
    "        \n",
    "\n",
    "model = Test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Test(\n",
       "  original_name=Test\n",
       "  (score4): Conv2d(original_name=Conv2d)\n",
       "  (score_fr): Conv2d(original_name=Conv2d)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "input_shape = [1, 23, 13, 19]\n",
    "input_data = torch.randn(input_shape)\n",
    "scripted_model = torch.jit.trace(model, input_data)\n",
    "scripted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IRModuleNode( {GlobalVar(main): FunctionNode([Var(input0, ty=TensorType([1, 23, 13, 19], float32)), Var(score4.weight, ty=TensorType([22, 23, 1, 1], float32)), Var(score4.bias, ty=TensorType([22], float32)), Var(score_fr.weight, ty=TensorType([21, 22, 1, 1], float32))], TensorType([1, 21, 13, 19], float32), CallNode(Op(nn.conv2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input0, ty=TensorType([1, 23, 13, 19], float32)), Var(score4.weight, ty=TensorType([22, 23, 1, 1], float32))], relay.attrs.Conv2DAttrs(000001F122E72048), [TensorType([1, 23, 13, 19], float32), TensorType([22, 23, 1, 1], float32)]), Var(score4.bias, ty=TensorType([22], float32))], relay.attrs.BiasAddAttrs(000001F122FEF698), [TensorType([1, 22, 13, 19], float32), TensorType([22], float32)]), Var(score_fr.weight, ty=TensorType([21, 22, 1, 1], float32))], relay.attrs.Conv2DAttrs(000001F122E71808), [TensorType([1, 22, 13, 19], float32), TensorType([21, 22, 1, 1], float32)]), [], (nullptr))})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.contrib import graph_runtime\n",
    "\n",
    "input_name = 'input0'\n",
    "shape_list = [(input_name, input_shape)]\n",
    "mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)\n",
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = mod['main']\n",
    "# visualize(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def work_on_fn(pass_cls):\n",
    "    def apply_pass(fn_or_mod):\n",
    "        if isinstance(fn_or_mod, tvm.IRModule):\n",
    "            return pass_cls()(fn_or_mod)\n",
    "        if isinstance(fn_or_mod, tvm.relay.Function):\n",
    "            return pass_cls()(\n",
    "                       tvm.IRModule({'main': fn_or_mod}))['main']\n",
    "        raise NotImplemented(\"unsupporded type {}\".format(type(fn_or_mod)))\n",
    "    return apply_pass\n",
    "\n",
    "infer_type = work_on_fn(tvm.relay.transform.InferType)\n",
    "to_graph_normal_form = work_on_fn(tvm.relay.transform.ToGraphNormalForm)\n",
    "dead_code_elimination = work_on_fn(tvm.relay.transform.DeadCodeElimination)\n",
    "eliminate_common_subexpr = work_on_fn(tvm.relay.transform.EliminateCommonSubexpr)\n",
    "\n",
    "class ShapeConstDedupMutator(tvm.relay.ExprMutator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.shape_consts = {}\n",
    "\n",
    "    def visit_call(self, call):\n",
    "        if (isinstance(call.op, tvm.ir.Op) \n",
    "            and call.op.name in {\"reshape\", \"broadcast_to\", \"collapse_sum_to\"}\n",
    "            and isinstance(call.args[1], tvm.relay.Constant)):\n",
    "            # assert list(call.attrs.newshape) == list(call.args[1].data.asnumpy())\n",
    "            new_fn = self.visit(call.op)\n",
    "            new_args = [self.visit(arg) for arg in call.args]\n",
    "            const = new_args[1]\n",
    "            assert const.data.dtype.startswith('int') and len(const.data.shape)==1\n",
    "            key = tuple(const.data.asnumpy())\n",
    "            if key in self.shape_consts:\n",
    "                new_args[1] = self.shape_consts[key]\n",
    "            else:\n",
    "                self.shape_consts[key] = new_args[1]\n",
    "            return tvm.relay.Call(new_fn, new_args, call.attrs)\n",
    "        return super().visit_call(call)\n",
    "\n",
    "\n",
    "class TransposeDedupMutator(tvm.relay.ExprMutator):\n",
    "    def visit_call(self, call):\n",
    "        if (isinstance(call.op, tvm.ir.Op) and call.op.name == \"transpose\"\n",
    "            and isinstance(call.args[0], tvm.relay.Call) \n",
    "            and isinstance(call.args[0].op, tvm.ir.Op) and call.args[0].op.name == \"transpose\"):\n",
    "            axes = [call.args[0].attrs.axes[int(i)] for i in call.attrs.axes]\n",
    "            new_inp = self.visit(call.args[0].args[0])\n",
    "            if axes == list(range(len(axes))): # neutral permutation, should really do this separately...\n",
    "                return new_inp\n",
    "            return tvm.relay.transpose(new_inp, axes)\n",
    "        return super().visit_call(call)\n",
    "\n",
    "#@tvm.relay.transform.function_pass(opt_level=1)\n",
    "#def TransposeDedup(fn, mod, ctx):\n",
    "#    return TransposeDedupMutator().visit(fn)\n",
    "\n",
    "class ZeroZapp(tvm.relay.dataflow_pattern.DFPatternCallback):\n",
    "    def __init__(self):\n",
    "        self.zeros = tvm.relay.dataflow_pattern.is_op(\"zeros\")(tvm.relay.dataflow_pattern.wildcard())\n",
    "        self.other_tensor = tvm.relay.dataflow_pattern.wildcard()\n",
    "        self.pattern = (self.zeros + self.other_tensor) | (self.other_tensor + self.zeros)\n",
    "        self.require_type = True\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        rt = node_map[self.pattern][0]\n",
    "        ot = node_map[self.other_tensor][0]\n",
    "        if (ot._checked_type_ == rt._checked_type_):\n",
    "            return ot\n",
    "        else:\n",
    "            return tvm.relay.broadcast_to(ot, list(rt._checked_type_.shape))\n",
    "\n",
    "class ZeroZapp(tvm.relay.dataflow_pattern.DFPatternCallback):\n",
    "    def __init__(self):\n",
    "        self.ones = tvm.relay.dataflow_pattern.is_op(\"zeros\")(tvm.relay.dataflow_pattern.wildcard()) | tvm.relay.dataflow_pattern.is_constant()\n",
    "        self.other_tensor = tvm.relay.dataflow_pattern.wildcard()\n",
    "        self.pattern = (self.ones + self.other_tensor) | (self.other_tensor + self.ones)\n",
    "        self.require_type = True\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        rt = node_map[self.pattern][0]\n",
    "        ones = node_map[self.ones][0]\n",
    "        ot = node_map[self.other_tensor][0]\n",
    "        if isinstance(ones, tvm.relay.Constant):\n",
    "            val = ones.data.asnumpy()\n",
    "            if not ((val == 0) if numpy.isscalar(val) else (val == 0).all()):\n",
    "                return rt\n",
    "        # I don't know why I don't reliably get checked types here...\n",
    "        if (((rt._checked_type_ is not None) and (ot._checked_type_ == rt._checked_type_))\n",
    "            or (rt.type_args[0] == rt.type_args[1])):\n",
    "            return ot\n",
    "        elif (rt._checked_type_ is not None):\n",
    "            return tvm.relay.broadcast_to(ot, list(rt._checked_type_.shape))\n",
    "        return rt\n",
    "\n",
    "class OneZapp(tvm.relay.dataflow_pattern.DFPatternCallback):\n",
    "    def __init__(self):\n",
    "        self.ones = tvm.relay.dataflow_pattern.is_op(\"ones\")(tvm.relay.dataflow_pattern.wildcard()) | tvm.relay.dataflow_pattern.is_constant()\n",
    "        self.other_tensor = tvm.relay.dataflow_pattern.wildcard()\n",
    "        self.pattern = (self.ones * self.other_tensor) | (self.other_tensor * self.ones)\n",
    "        self.require_type = True\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        global val\n",
    "        rt = node_map[self.pattern][0]\n",
    "        ones = node_map[self.ones][0]\n",
    "        ot = node_map[self.other_tensor][0]\n",
    "        if isinstance(ones, tvm.relay.Constant):\n",
    "            val = ones.data.asnumpy()\n",
    "            if not ((val == 1) if numpy.isscalar(val) else (val == 1).all()):\n",
    "                return rt\n",
    "        if (((rt._checked_type_ is not None) and (ot._checked_type_ == rt._checked_type_))\n",
    "            or (rt.type_args[0] == rt.type_args[1])):\n",
    "            return ot\n",
    "        if (rt._checked_type_ is not None):\n",
    "            return tvm.relay.broadcast_to(ot, list(rt._checked_type_.shape))\n",
    "        return rt\n",
    "\n",
    "\n",
    "class LikeZapp(tvm.relay.dataflow_pattern.DFPatternCallback):\n",
    "    def __init__(self):\n",
    "        self.translations_with_dt = {'zeros_like': tvm.relay.zeros,\n",
    "                                     'ones_like': tvm.relay.ones}\n",
    "        self.data_tensor = tvm.relay.dataflow_pattern.wildcard()\n",
    "        self.pattern_tensor = tvm.relay.dataflow_pattern.wildcard()\n",
    "        self.pattern = ((tvm.relay.dataflow_pattern.is_op(\"zeros_like\")\n",
    "                        | tvm.relay.dataflow_pattern.is_op(\"ones_like\")\n",
    "                        )(self.data_tensor)\n",
    "                        ) | ((\n",
    "                        tvm.relay.dataflow_pattern.is_op(\"collapse_sum_like\")\n",
    "                        | tvm.relay.dataflow_pattern.is_op(\"reshape_like\")\n",
    "                        | tvm.relay.dataflow_pattern.is_op(\"broadcast_to_like\")\n",
    "                       )(self.data_tensor, self.pattern_tensor))\n",
    "        self.require_type = True\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        data = node_map[self.data_tensor][0]\n",
    "        res = node_map[self.pattern][0]\n",
    "        if res.op.name in self.translations_with_dt:\n",
    "            ret = self.translations_with_dt[res.op.name](list(res.type_args[0].shape),\n",
    "                                                              res.type_args[0].dtype) # which dtype?\n",
    "            return ret\n",
    "        if (res.type_args[0] is not None and res.type_args[0] == res.type_args[1]):\n",
    "            return data\n",
    "        if res.op.name == 'broadcast_to_like':\n",
    "            return tvm.relay.broadcast_to(data, list(res.type_args[1].shape))\n",
    "        if res.op.name == 'reshape_like':\n",
    "            return tvm.relay.reshape(data, list(res.type_args[1].shape))\n",
    "        if res.op.name == 'collapse_sum_like':\n",
    "            return tvm.relay.collapse_sum_to(data, list(res.type_args[1].shape))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = TransposeDedupMutator().visit(fn)\n",
    "fn = infer_type(fn)\n",
    "\n",
    "output_type = fn.body.checked_type\n",
    "\n",
    "if isinstance(output_type, tvm.relay.TensorType):\n",
    "    gr_out = tvm.relay.var(\"gr:out\", output_type)\n",
    "    fn_for_gr = tvm.relay.Function(list(fn.params) + [gr_out], tvm.relay.sum(fn.body * gr_out))\n",
    "else:\n",
    "    # we can try to handle tuples of tensors, but our nesting patience ends there\n",
    "    assert (isinstance(output_type, tvm.relay.TupleType) and\n",
    "            all([isinstance(f, tvm.relay.TensorType) for f in output_type.fields]))\n",
    "    gr_outs = [tvm.relay.var(f\"gr:out:{i}\", t) for i, t in enumerate(output_type.fields)]\n",
    "    prods_with_gr_out = [tvm.relay.sum(tvm.relay.TupleGetItem(fn.body, i) * go_i)\n",
    "                         for i, go_i in enumerate(gr_outs)]\n",
    "    s = prods_with_gr_out[0]\n",
    "    for p in prods_with_gr_out[1:]:\n",
    "        s = s + p\n",
    "    fn_for_gr = tvm.relay.Function(list(fn.params) + gr_outs, s)\n",
    "fn_for_gr = infer_type(fn_for_gr)\n",
    "# visualize(fn_for_gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grfn = tvm.relay.transform.gradient(fn_for_gr, mode='first_order')\n",
    "grfn = to_graph_normal_form(grfn)\n",
    "\n",
    "# Now we have (sum(orig_out * grad_out), (grad_inp_1, ..., grad_inp_n, grad_grad_out, gr_dropout ...))\n",
    "# but we only want orig_out and grad_inp_1, ..., grad_inp_n\n",
    "def is_aux_input(p):\n",
    "    return p.name_hint.startswith('dropout:') or p.name_hint.startswith('gr:out:')\n",
    "\n",
    "# the gr_out and dropout parameters will have gradients computed, but we do not want that\n",
    "grads_to_keep = tvm.relay.Tuple([g for p, g in zip(grfn.params, grfn.body.fields[1].fields)\n",
    "                                   if not is_aux_input(p)])\n",
    "\n",
    "assert grfn.body.fields[0].op.name == 'sum'\n",
    "assert grfn.body.fields[0].args[0].op.name == 'multiply'\n",
    "if isinstance(output_type, tvm.relay.TensorType):\n",
    "    orig_out = grfn.body.fields[0].args[0].args[0]\n",
    "else:\n",
    "    assert isinstance(output_type, tvm.relay.TupleType)\n",
    "    orig_out = grfn.body.fields[0].args[0].args[0].tuple_value\n",
    "out_and_grad = tvm.relay.Tuple([orig_out, grads_to_keep])\n",
    "out_and_grad_fn = tvm.relay.Function(grfn.params, out_and_grad)\n",
    "out_and_grad_fn = infer_type(out_and_grad_fn)\n",
    "out_and_grad_fn = dead_code_elimination(out_and_grad_fn)\n",
    "out_and_grad_fn = eliminate_common_subexpr(out_and_grad_fn)\n",
    "out_and_grad_fn = infer_type(out_and_grad_fn)\n",
    "# out_and_grad_fn = tvm.relay.dataflow_pattern.rewrite(LikeZapp(), out_and_grad_fn)\n",
    "# out_and_grad_fn = infer_type(out_and_grad_fn)\n",
    "# out_and_grad_fn = tvm.relay.dataflow_pattern.rewrite(ZeroZapp(), out_and_grad_fn)\n",
    "# out_and_grad_fn = infer_type(out_and_grad_fn)\n",
    "# out_and_grad_fn = tvm.relay.dataflow_pattern.rewrite(OneZapp(), out_and_grad_fn)\n",
    "# out_and_grad_fn = infer_type(out_and_grad_fn)\n",
    "# out_and_grad_fn = tvm.relay.dataflow_pattern.rewrite(OneZapp(), out_and_grad_fn)\n",
    "# out_and_grad_fn = infer_type(out_and_grad_fn)\n",
    "# out_and_grad_fn = dead_code_elimination(out_and_grad_fn)\n",
    "# out_and_grad_fn = eliminate_common_subexpr(out_and_grad_fn)\n",
    "\n",
    "# tvm.relay.analysis.all_type_vars(grfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{CallNode(Op(nn.conv2d), [CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input0, ty=TensorType([1, 23, 13, 19], float32)), Var(score4.weight, ty=TensorType([22, 23, 1, 1], float32))], relay.attrs.Conv2DAttrs(000001F122E72048), [TensorType([1, 23, 13, 19], float32), TensorType([22, 23, 1, 1], float32)]), Var(score4.bias, ty=TensorType([22], float32))], relay.attrs.BiasAddAttrs(000001F122FEF698), [TensorType([1, 22, 13, 19], float32), TensorType([22], float32)]), Var(score_fr.weight, ty=TensorType([21, 22, 1, 1], float32))], relay.attrs.Conv2DAttrs(000001F122E71808), [TensorType([1, 22, 13, 19], float32), TensorType([21, 22, 1, 1], float32)]): {'color': 'blue'},\n",
       " CallNode(Op(nn.bias_add), [CallNode(Op(nn.conv2d), [Var(input0, ty=TensorType([1, 23, 13, 19], float32)), Var(score4.weight, ty=TensorType([22, 23, 1, 1], float32))], relay.attrs.Conv2DAttrs(000001F122E72048), [TensorType([1, 23, 13, 19], float32), TensorType([22, 23, 1, 1], float32)]), Var(score4.bias, ty=TensorType([22], float32))], relay.attrs.BiasAddAttrs(000001F122FEF698), [TensorType([1, 22, 13, 19], float32), TensorType([22], float32)]): {'color': 'blue'},\n",
       " CallNode(Op(nn.conv2d), [Var(input0, ty=TensorType([1, 23, 13, 19], float32)), Var(score4.weight, ty=TensorType([22, 23, 1, 1], float32))], relay.attrs.Conv2DAttrs(000001F122E72048), [TensorType([1, 23, 13, 19], float32), TensorType([22, 23, 1, 1], float32)]): {'color': 'blue'},\n",
       " Var(input0, ty=TensorType([1, 23, 13, 19], float32)): {'color': 'blue'},\n",
       " Var(score4.weight, ty=TensorType([22, 23, 1, 1], float32)): {'color': 'blue'},\n",
       " Var(score4.bias, ty=TensorType([22], float32)): {'color': 'blue'},\n",
       " Var(score_fr.weight, ty=TensorType([21, 22, 1, 1], float32)): {'color': 'blue'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_out = out_and_grad_fn.body.fields[0]\n",
    "grad_ins = out_and_grad_fn.body.fields[1]\n",
    "\n",
    "color_dict = {}\n",
    "def color(n, c):\n",
    "    if n in color_dict:\n",
    "        return\n",
    "    color_dict[n] = c\n",
    "    for a in getattr(n, 'args', []):\n",
    "        color(a, c)\n",
    "    for a in getattr(n, 'fields', []):\n",
    "        color(a, c)\n",
    "    for nam in ('body', 'tuple_value'):\n",
    "        b = getattr(n, nam, None)\n",
    "        if b is not None:\n",
    "            color(b, c)\n",
    "\n",
    "color(orig_out, {'color': 'red'})\n",
    "seen = set()\n",
    "def color_crossings(n, c):\n",
    "    if n in seen:\n",
    "        return\n",
    "    seen.add(n)\n",
    "    if n in color_dict:\n",
    "        color_dict[n] = c\n",
    "        return\n",
    "    for a in getattr(n, 'args', []):\n",
    "        color_crossings(a, c)\n",
    "    for a in getattr(n, 'fields', []):\n",
    "        color_crossings(a, c)\n",
    "    for nam in ('body', 'tuple_value'):\n",
    "        b = getattr(n, nam, None)\n",
    "        if b is not None:\n",
    "            color_crossings(b, c)\n",
    "\n",
    "color_crossings(grad_ins, {'color': 'blue'})\n",
    "# visualize(out_and_grad_fn, node_attr_dict=color_dict)\n",
    "color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_to_capture = [n for n, v in color_dict.items() \n",
    "                    if v['color'] == 'blue' and not isinstance(n, (tvm.relay.Constant, tvm.relay.Var))]\n",
    "capture_tup = tvm.relay.Tuple(nodes_to_capture)\n",
    "nodes_to_capture_idx = {n:i for i, n in enumerate(nodes_to_capture)}\n",
    "capture_vars = [tvm.relay.var(f\"input:captures:{i}\", type_annotation=nodes_to_capture[i].checked_type)\n",
    "                for i, n in enumerate(nodes_to_capture)]\n",
    "\n",
    "grads_in = out_and_grad_fn.body.fields[1]\n",
    "\n",
    "needed_vars = set()\n",
    "class GradientOnlyMutator(tvm.relay.ExprMutator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def visit_var(self, var):\n",
    "        needed_vars.add(var)\n",
    "        return var\n",
    "\n",
    "    def visit(self, expr):\n",
    "        if expr in nodes_to_capture_idx:\n",
    "            return capture_vars[nodes_to_capture_idx[expr]]\n",
    "        return super().visit(expr)\n",
    "\n",
    "grads_in_only = GradientOnlyMutator().visit(grads_in)\n",
    "gr_only_fn = tvm.relay.Function(sorted(needed_vars) + capture_vars, grads_in_only)\n",
    "gr_only_fn = infer_type(gr_only_fn)\n",
    "\n",
    "# TODO: check against output of original\n",
    "fn_for_gr_input_names = {p.name_hint for p in fn_for_gr.params}\n",
    "needed_var_names = {v.name_hint for v in needed_vars}\n",
    "\n",
    "assert needed_var_names <= fn_for_gr_input_names\n",
    "inputs_to_keep = [n for n in needed_vars if not is_aux_input(n)]\n",
    "\n",
    "capture_tup = tvm.relay.Tuple([n for n in nodes_to_capture])\n",
    "fw_and_cap_params = [p for p in out_and_grad_fn.params if not p.name_hint.startswith('gr:out:')]\n",
    "\n",
    "fw_and_cap_fn = tvm.relay.Function(fw_and_cap_params,\n",
    "                                   tvm.relay.Tuple((out_and_grad_fn.body.fields[0],) + (capture_tup,)))\n",
    "# visualize(gr_only_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find config for target=cuda -keys=cuda,gpu -max_num_threads=1024 -model=unknown -thread_warp_size=32, workload=('conv2d_nchw.cuda', ('TENSOR', (1, 23, 13, 19), 'float32'), ('TENSOR', (22, 23, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=cuda -keys=cuda,gpu -max_num_threads=1024 -model=unknown -thread_warp_size=32, workload=('conv2d_nchw.cuda', ('TENSOR', (1, 22, 13, 19), 'float32'), ('TENSOR', (21, 22, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: legacy graph runtime behaviour of producing json / lib / params will be  removed in the next release. Please see documents of tvm.contrib.graph_runtime.GraphModule for the  new recommended usage.\n",
      "  del sys.path[0]\n",
      "Cannot find config for target=cuda -keys=cuda,gpu -max_num_threads=1024 -model=unknown -thread_warp_size=32, workload=('group_conv2d_nchw.cuda', ('TENSOR', (1, 23, 13, 19), 'float32'), ('TENSOR', (506, 1, 13, 19), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 23, 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=cuda -keys=cuda,gpu -max_num_threads=1024 -model=unknown -thread_warp_size=32, workload=('group_conv2d_nchw.cuda', ('TENSOR', (1, 22, 13, 19), 'float32'), ('TENSOR', (462, 1, 13, 19), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 22, 'float32'). A fallback configuration is used, which may bring great performance regression.\n"
     ]
    },
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  File \"F:\\tvm_0.7_vs2019\\src\\ir\\error.cc\", line 132\nTVMError: \nError(s) have occurred. The program has been annotated with them:\n\nIn `main`: \n#[version = \"0.0.5\"]\nfn (%score4.bias: Tensor[(22), float32], %score_fr.weight: Tensor[(21, 22, 1, 1), float32], %score4.weight: Tensor[(22, 23, 1, 1), float32], %input0: Tensor[(1, 23, 13, 19), float32], %gr:out: Tensor[(1, 21, 13, 19), float32], %input:captures:0: Tensor[(1, 21, 13, 19), float32], %input:captures:1: Tensor[(1, 22, 13, 19), float32], %input:captures:2: Tensor[(1, 22, 13, 19), float32]) -> (Tensor[(1, 23, 13, 19), float32], Tensor[(22, 23, 1, 1), float32], Tensor[(22), float32], Tensor[(21, 22, 1, 1), float32], Tensor[(1, 21, 13, 19), float32]) {\n  %0 = zeros_like(%input0);\n  %1 = zeros_like(%input:captures:2);\n  %2 = zeros_like(%input:captures:1);\n  %3 = zeros_like(%input:captures:0);\n  %4 = multiply(%input:captures:0, %gr:out);\n  %5 = zeros_like(%4);\n  %6 = sum(%4);\n  %7 = ones_like(%6);\n  %8 = expand_dims(%7, axis=0);\n  %9 = expand_dims(%8, axis=1);\n  %10 = expand_dims(%9, axis=2);\n  %11 = expand_dims(%10, axis=3);\n  %12 = broadcast_to_like(%11, %4);\n  %13 = add(%5, %12);\n  %14 = multiply(%13, %gr:out);\n  %15 = collapse_sum_like(%14, %input:captures:0);\n  %16 = add(%3, %15);\n  %17 = nn.conv2d_transpose(%16, %score_fr.weight, padding=[0, 0, 0, 0]);\n  %18 = add(%2, %17);\n  %19 = collapse_sum_like(%18, %input:captures:2);\n  %20 = add(%1, %19);\n  %21 = nn.conv2d_transpose(%20, %score4.weight, padding=[0, 0, 0, 0]);\n  %22 = add(%0, %21);\n  %23 = zeros_like(%score4.weight);\n  %24 = reshape(%input0, newshape=[1, -1, 0, 0]);\n  %25 = tile(%20, reps=[1, 23, 1, 1]);\n  %26 = reshape(%25, newshape=[-1, 1, 0, 0]);\n  %27 = nn.conv2d(%24, %26, padding=[0, 0, 0, 0], groups=23);\n  %28 = reshape(%27, newshape=[1, 23, 22, 1, 1]);\n  %29 = sum(%28, axis=[0]);\n  %30 = transpose(%29, axes=[1, 0, 2, 3]);\n  %31 = add(%23, %30);\n  %32 = zeros_like(%score4.bias);\n  %33 = expand_dims(%32, axis=0, num_newaxis=3);\n  %34 = layout_transform(%33, src_layout=\"CHWN\", dst_layout=\"NCHW\");\n  %35 = sum(%18, axis=[0, 2, 3], exclude=True);\n  %36 = add(%34, %35) tensor type `Tensor[(22, 1, 13, 19), float32]` has 4 dimensions, while `Tensor[(22), float32]` has 1 dimensions; unable to unify: `Tensor[(22, 1, 13, 19), float32]` and `Tensor[(22), float32]`; ;\n  %37 = zeros_like(%score_fr.weight);\n  %38 = reshape(%input:captures:1, newshape=[1, -1, 0, 0]);\n  %39 = tile(%16, reps=[1, 22, 1, 1]);\n  %40 = reshape(%39, newshape=[-1, 1, 0, 0]);\n  %41 = nn.conv2d(%38, %40, padding=[0, 0, 0, 0], groups=22);\n  %42 = reshape(%41, newshape=[1, 22, 21, 1, 1]);\n  %43 = sum(%42, axis=[0]);\n  %44 = transpose(%43, axes=[1, 0, 2, 3]);\n  %45 = add(%37, %44);\n  %46 = zeros_like(%gr:out);\n  %47 = multiply(%13, %input:captures:0);\n  %48 = collapse_sum_like(%47, %gr:out);\n  %49 = add(%46, %48);\n  (%22, %31, %36, %45, %49)\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a40ed860004d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m                                      \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                                      \u001b[0mtarget_host\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_host\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                                      params={})\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mgr_only_compiled_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_runtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mgr_only_compiled_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# we do have funny const tensors from TVM :/\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tvm-0.7.0-py3.7-win-amd64.egg\\tvm\\relay\\build_module.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(mod, target, target_host, params, mod_name)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtophub_context\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[0mbld_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBuildModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m         \u001b[0mgraph_json\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbld_mod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m         \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_graph_runtime_factory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphRuntimeFactoryModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_json\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tvm-0.7.0-py3.7-win-amd64.egg\\tvm\\relay\\build_module.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, mod, target, target_host, params)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# Build the IR module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_host\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m         \u001b[1;31m# Get artifacts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mgraph_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tvm-0.7.0-py3.7-win-amd64.egg\\tvm\\_ffi\\_ctypes\\packed_func.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         ):\n\u001b[1;32m--> 237\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTVMError\u001b[0m: Traceback (most recent call last):\n  File \"F:\\tvm_0.7_vs2019\\src\\ir\\error.cc\", line 132\nTVMError: \nError(s) have occurred. The program has been annotated with them:\n\nIn `main`: \n#[version = \"0.0.5\"]\nfn (%score4.bias: Tensor[(22), float32], %score_fr.weight: Tensor[(21, 22, 1, 1), float32], %score4.weight: Tensor[(22, 23, 1, 1), float32], %input0: Tensor[(1, 23, 13, 19), float32], %gr:out: Tensor[(1, 21, 13, 19), float32], %input:captures:0: Tensor[(1, 21, 13, 19), float32], %input:captures:1: Tensor[(1, 22, 13, 19), float32], %input:captures:2: Tensor[(1, 22, 13, 19), float32]) -> (Tensor[(1, 23, 13, 19), float32], Tensor[(22, 23, 1, 1), float32], Tensor[(22), float32], Tensor[(21, 22, 1, 1), float32], Tensor[(1, 21, 13, 19), float32]) {\n  %0 = zeros_like(%input0);\n  %1 = zeros_like(%input:captures:2);\n  %2 = zeros_like(%input:captures:1);\n  %3 = zeros_like(%input:captures:0);\n  %4 = multiply(%input:captures:0, %gr:out);\n  %5 = zeros_like(%4);\n  %6 = sum(%4);\n  %7 = ones_like(%6);\n  %8 = expand_dims(%7, axis=0);\n  %9 = expand_dims(%8, axis=1);\n  %10 = expand_dims(%9, axis=2);\n  %11 = expand_dims(%10, axis=3);\n  %12 = broadcast_to_like(%11, %4);\n  %13 = add(%5, %12);\n  %14 = multiply(%13, %gr:out);\n  %15 = collapse_sum_like(%14, %input:captures:0);\n  %16 = add(%3, %15);\n  %17 = nn.conv2d_transpose(%16, %score_fr.weight, padding=[0, 0, 0, 0]);\n  %18 = add(%2, %17);\n  %19 = collapse_sum_like(%18, %input:captures:2);\n  %20 = add(%1, %19);\n  %21 = nn.conv2d_transpose(%20, %score4.weight, padding=[0, 0, 0, 0]);\n  %22 = add(%0, %21);\n  %23 = zeros_like(%score4.weight);\n  %24 = reshape(%input0, newshape=[1, -1, 0, 0]);\n  %25 = tile(%20, reps=[1, 23, 1, 1]);\n  %26 = reshape(%25, newshape=[-1, 1, 0, 0]);\n  %27 = nn.conv2d(%24, %26, padding=[0, 0, 0, 0], groups=23);\n  %28 = reshape(%27, newshape=[1, 23, 22, 1, 1]);\n  %29 = sum(%28, axis=[0]);\n  %30 = transpose(%29, axes=[1, 0, 2, 3]);\n  %31 = add(%23, %30);\n  %32 = zeros_like(%score4.bias);\n  %33 = expand_dims(%32, axis=0, num_newaxis=3);\n  %34 = layout_transform(%33, src_layout=\"CHWN\", dst_layout=\"NCHW\");\n  %35 = sum(%18, axis=[0, 2, 3], exclude=True);\n  %36 = add(%34, %35) tensor type `Tensor[(22, 1, 13, 19), float32]` has 4 dimensions, while `Tensor[(22), float32]` has 1 dimensions; unable to unify: `Tensor[(22, 1, 13, 19), float32]` and `Tensor[(22), float32]`; ;\n  %37 = zeros_like(%score_fr.weight);\n  %38 = reshape(%input:captures:1, newshape=[1, -1, 0, 0]);\n  %39 = tile(%16, reps=[1, 22, 1, 1]);\n  %40 = reshape(%39, newshape=[-1, 1, 0, 0]);\n  %41 = nn.conv2d(%38, %40, padding=[0, 0, 0, 0], groups=22);\n  %42 = reshape(%41, newshape=[1, 22, 21, 1, 1]);\n  %43 = sum(%42, axis=[0]);\n  %44 = transpose(%43, axes=[1, 0, 2, 3]);\n  %45 = add(%37, %44);\n  %46 = zeros_like(%gr:out);\n  %47 = multiply(%13, %input:captures:0);\n  %48 = collapse_sum_like(%47, %gr:out);\n  %49 = add(%46, %48);\n  (%22, %31, %36, %45, %49)\n}"
     ]
    }
   ],
   "source": [
    "fw_and_cap_fn_flattened = tvm.relay.Function(fw_and_cap_fn.params, tvm.relay.Tuple([fw_and_cap_fn.body.fields[0]]\n",
    "                                                + list(fw_and_cap_fn.body.fields[1].fields)))\n",
    "\n",
    "target = tvm.target.cuda()\n",
    "target_host = 'llvm'\n",
    "ctx = tvm.context(str(target), 0)\n",
    "\n",
    "fw_and_cap_mod = tvm.IRModule({\"main\": fw_and_cap_fn_flattened})\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    graph, lib, params = tvm.relay.build(fw_and_cap_mod,\n",
    "                                         target=target,\n",
    "                                         target_host=target_host,\n",
    "                                         params={})\n",
    "fw_and_cap_compiled_module = tvm.contrib.graph_runtime.create(graph, lib, ctx)\n",
    "fw_and_cap_compiled_module.set_input(**params)\n",
    "\n",
    "gr_only_mod = tvm.IRModule({\"main\": gr_only_fn})\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    graph, lib, params = tvm.relay.build(gr_only_mod,\n",
    "                                     target=target,\n",
    "                                     target_host=target_host,\n",
    "                                     params={})\n",
    "gr_only_compiled_module = tvm.contrib.graph_runtime.create(graph, lib, ctx)\n",
    "gr_only_compiled_module.set_input(**params) # we do have funny const tensors from TVM :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils import dlpack\n",
    "\n",
    "def tensor_to_tvm(t):\n",
    "    return tvm.nd.from_dlpack(dlpack.to_dlpack(t))\n",
    "def tensor_from_tvm(a):\n",
    "    return (dlpack.from_dlpack(a.to_dlpack()))\n",
    "\n",
    "model_params_tvm = {k: tensor_to_tvm(v) for k, v in model.state_dict().items()}\n",
    "\n",
    "model.cuda()\n",
    "inp_c = input_data.cuda()\n",
    "inp_tvm = tensor_to_tvm(inp_c)\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "\n",
    "fw_and_cap_compiled_module.set_input(input_name, inp_tvm)\n",
    "fw_and_cap_compiled_module.set_input(**model_params_tvm)\n",
    "fw_and_cap_compiled_module.run()\n",
    "# inp_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "model.train()\n",
    "numpy.abs(fw_and_cap_compiled_module.get_output(0).asnumpy()-model(inp_c).detach().cpu().numpy()).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gr_out_c = torch.randn([1, 21, 28, 40]).cuda()\n",
    "\n",
    "num_captures = len(capture_vars)\n",
    "num_regular_outputs = len(fw_and_cap_fn_flattened.body.fields) - num_captures\n",
    "captured_values = {v.name_hint: fw_and_cap_compiled_module.get_output(num_regular_outputs + i) for i, v in enumerate(capture_vars)}\n",
    "\n",
    "gr_only_compiled_module.set_input(**model_params_tvm)\n",
    "gr_only_compiled_module.set_input(**captured_values)\n",
    "gr_only_compiled_module.set_input('gr:out', tensor_to_tvm(gr_out_c))\n",
    "gr_only_compiled_module.set_input(input_name, inp_tvm)\n",
    "gr_only_compiled_module.run()\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "model.train()\n",
    "inp_c_rq = inp_c.requires_grad_()\n",
    "for p in model.parameters():\n",
    "    p.requires_grad_()\n",
    "res = model(inp_c_rq)\n",
    "grads_pt = torch.autograd.grad(res, [inp_c_rq] + list(model.parameters()), gr_out_c, allow_unused=True, retain_graph=True)\n",
    "grads_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, g_pt in enumerate(grads_pt):\n",
    "    print(numpy.abs(gr_only_compiled_module.get_output(i).asnumpy() - g_pt.cpu().numpy()).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w = gr_only_compiled_module.get_output(1)\n",
    "w = tensor_from_tvm(w)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
